import os
import asyncio
import httpx
from io import BytesIO
from typing import Optional, List
from PIL import Image
from app.config import settings
from app.models.schemas import Stage2Output, Stage3Output
from app.services.openrouter_client import OpenRouterClient


class Stage3ImageGenerationService:
    def __init__(self, client: Optional[OpenRouterClient] = None, output_dir: str = "./output/images"):
        self.client = client or OpenRouterClient()
        self.output_dir = output_dir
        os.makedirs(self.output_dir, exist_ok=True)
    
    async def generate_image_from_prompt(
        self,
        prompt: str,
        size: str = "1024x1024",
        quality: str = "standard",
        model: str = "openai/dall-e-3",
    ) -> bytes:
        """
        é€šè¿‡ OpenRouter èŠå¤©å®Œæˆæ¥å£ç”Ÿæˆå›¾åƒ
        é€‚ç”¨äº GPT-5 Image Mini ç­‰å¤šæ¨¡æ€æ¨¡å‹
        """
        headers = {
            "Authorization": f"Bearer {self.client.api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://github.com/hyt1004/big-niu",
            "X-Title": "Big Niu Text-to-Video",
        }
        
        # ä½¿ç”¨èŠå¤©å®Œæˆæ¥å£ï¼Œè€Œä¸æ˜¯å›¾åƒç”Ÿæˆæ¥å£
        # ç›´æ¥ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼çš„ content
        payload = {
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": f"Generate an image: {prompt}"
                }
            ],
            "max_tokens": 4000,
        }
        
        async with httpx.AsyncClient(timeout=120.0) as client:
            response = await client.post(
                f"{self.client.base_url}/chat/completions",
                headers=headers,
                json=payload,
            )
            
            if response.status_code != 200:
                error_detail = response.text
                raise ValueError(f"API Error {response.status_code}: {error_detail}")
            
            result = response.json()
            
            # ä»å“åº”ä¸­æå–å›¾åƒ
            # GPT-5 Image æ¨¡å‹ä¼šåœ¨ message.images ä¸­è¿”å›å›¾åƒ
            message = result["choices"][0]["message"]
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å›¾åƒæ•°æ®
            if "images" in message and len(message["images"]) > 0:
                image_data = message["images"][0]
                image_url = image_data["image_url"]["url"]
                
                # å¦‚æœæ˜¯ base64 ç¼–ç çš„å›¾åƒ
                if image_url.startswith("data:image"):
                    import base64
                    # æå– base64 æ•°æ®éƒ¨åˆ†
                    base64_data = image_url.split(",")[1]
                    return base64.b64decode(base64_data)
                else:
                    # å¦‚æœæ˜¯ URLï¼Œä¸‹è½½å›¾åƒ
                    image_response = await client.get(image_url)
                    image_response.raise_for_status()
                    return image_response.content
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å›¾åƒï¼ŒæŠ›å‡ºé”™è¯¯
            raise ValueError(f"No image found in response. Message keys: {message.keys()}")
    
    def save_image(self, image_data: bytes, filename: str) -> str:
        filepath = os.path.join(self.output_dir, filename)
        
        image = Image.open(BytesIO(image_data))
        image.save(filepath, format='PNG')
        
        return filepath
    
    async def generate_scene_image(
        self,
        stage2_output: Stage2Output,
        size: str = "1024x1024",
        quality: str = "standard",
        model: Optional[str] = None,
    ) -> Stage3Output:
        prompt = stage2_output.image_prompt
        
        if stage2_output.negative_prompt:
            prompt = f"{prompt}. Avoid: {stage2_output.negative_prompt}"
        
        model_to_use = model or settings.image_generation_model
        
        image_data = await self.generate_image_from_prompt(
            prompt=prompt,
            size=size,
            quality=quality,
            model=model_to_use,
        )
        
        filename = f"{stage2_output.scene_id}.png"
        image_path = self.save_image(image_data, filename)
        
        image = Image.open(image_path)
        width, height = image.size
        
        return Stage3Output(
            scene_id=stage2_output.scene_id,
            image_path=image_path,
            image_url=None,
            width=width,
            height=height,
            generation_params={
                "model": model_to_use,
                "size": size,
                "quality": quality,
                "prompt": prompt,
            }
        )
    
    async def generate_all_images(
        self,
        stage2_outputs: List[Stage2Output],
        size: str = "1024x1024",
        quality: str = "standard",
        model: Optional[str] = None,
        concurrent: bool = True,
    ) -> List[Stage3Output]:
        """
        ç”Ÿæˆæ‰€æœ‰åœºæ™¯çš„å›¾åƒ
        
        Args:
            stage2_outputs: Stage2 è¾“å‡ºåˆ—è¡¨
            size: å›¾åƒå°ºå¯¸
            quality: å›¾åƒè´¨é‡
            model: æ¨¡å‹åç§°
            concurrent: æ˜¯å¦å¹¶å‘æ‰§è¡Œï¼ˆé»˜è®¤Trueï¼Œæå‡3å€é€Ÿåº¦ï¼‰
        
        Returns:
            Stage3Output åˆ—è¡¨
        """
        if concurrent:
            # å¹¶å‘æ‰§è¡Œï¼šåŒæ—¶å‘èµ·æ‰€æœ‰è¯·æ±‚ï¼Œå¤§å¹…æå‡é€Ÿåº¦
            print(f"ğŸš€ å¹¶å‘æ¨¡å¼ï¼šåŒæ—¶ç”Ÿæˆ {len(stage2_outputs)} å¼ å›¾åƒ")
            
            tasks = [
                self.generate_scene_image(
                    stage2_output=output,
                    size=size,
                    quality=quality,
                    model=model,
                )
                for output in stage2_outputs
            ]
            
            # asyncio.gather å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # æ£€æŸ¥é”™è¯¯
            final_results = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    scene_id = stage2_outputs[i].scene_id
                    print(f"âŒ {scene_id} ç”Ÿæˆå¤±è´¥: {result}")
                    raise result
                else:
                    final_results.append(result)
            
            return final_results
        else:
            # ä¸²è¡Œæ‰§è¡Œï¼šé€ä¸ªç”Ÿæˆï¼ˆç”¨äºè°ƒè¯•æˆ–APIé™æµï¼‰
            print(f"ğŸŒ ä¸²è¡Œæ¨¡å¼ï¼šä¾æ¬¡ç”Ÿæˆ {len(stage2_outputs)} å¼ å›¾åƒ")
            
            results = []
            for i, stage2_output in enumerate(stage2_outputs, 1):
                try:
                    print(f"ğŸ“¸ æ­£åœ¨ç”Ÿæˆ {i}/{len(stage2_outputs)}: {stage2_output.scene_id}")
                    result = await self.generate_scene_image(
                        stage2_output=stage2_output,
                        size=size,
                        quality=quality,
                        model=model,
                    )
                    results.append(result)
                    print(f"âœ… {stage2_output.scene_id} å®Œæˆ")
                except Exception as e:
                    print(f"âŒ {stage2_output.scene_id} å¤±è´¥: {e}")
                    raise
            
            return results
